{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zgvMV03QcLG",
        "outputId": "db445650-e727-4082-a840-c447da771d8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (569, 31)\n",
            "\n",
            "Training Models and Calculating Metrics...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [09:09:36] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Model Comparison Table for README ===\n",
            "                     Accuracy     AUC  Precision  Recall  F1 Score     MCC\n",
            "Logistic Regression    0.9737  0.9974     0.9722  0.9859    0.9790  0.9439\n",
            "Decision Tree          0.9474  0.9440     0.9577  0.9577    0.9577  0.8880\n",
            "KNN                    0.9474  0.9820     0.9577  0.9577    0.9577  0.8880\n",
            "Naive Bayes            0.9649  0.9974     0.9589  0.9859    0.9722  0.9253\n",
            "Random Forest          0.9649  0.9953     0.9589  0.9859    0.9722  0.9253\n",
            "XGBoost                0.9561  0.9908     0.9583  0.9718    0.9650  0.9064\n",
            "\n",
            "[SUCCESS] 'model_bundle.joblib' saved. Download this file for your Streamlit app.\n",
            "[SUCCESS] 'test_sample.csv' saved. Use this to test your Streamlit upload.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# ML ASSIGNMENT 2 - TRAINING PIPELINE\n",
        "# ==========================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
        "import joblib\n",
        "\n",
        "# Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# 1. Load Dataset (Meeting criteria: >12 features, >500 instances)\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "\n",
        "# 2. Preprocessing\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 3. Initialize Models [cite: 34, 35, 36, 37, 38, 39]\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "# Dictionary to store results and trained models\n",
        "results = {}\n",
        "trained_models = {}\n",
        "\n",
        "print(\"\\nTraining Models and Calculating Metrics...\\n\")\n",
        "\n",
        "# 4. Train and Evaluate [cite: 40]\n",
        "for name, model in models.items():\n",
        "    # Train\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, \"predict_proba\") else y_pred\n",
        "\n",
        "    # Calculate Metrics [cite: 41, 42, 43, 44, 45, 46]\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"AUC\": roc_auc_score(y_test, y_proba),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1 Score\": f1_score(y_test, y_pred),\n",
        "        \"MCC\": matthews_corrcoef(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    results[name] = metrics\n",
        "    trained_models[name] = model\n",
        "\n",
        "# 5. Display Comparison Table\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"=== Model Comparison Table for README ===\")\n",
        "print(results_df.round(4))\n",
        "\n",
        "# 6. Save Models and Scaler for Streamlit App [cite: 55]\n",
        "# We bundle everything into one file for easier handling\n",
        "bundle = {\n",
        "    \"models\": trained_models,\n",
        "    \"scaler\": scaler,\n",
        "    \"feature_names\": list(X.columns)\n",
        "}\n",
        "\n",
        "joblib.dump(bundle, 'model_bundle.joblib')\n",
        "print(\"\\n[SUCCESS] 'model_bundle.joblib' saved. Download this file for your Streamlit app.\")\n",
        "\n",
        "# Generate a sample CSV for testing the app later\n",
        "test_sample = X_test.copy()\n",
        "test_sample['target'] = y_test\n",
        "test_sample.head(20).to_csv(\"test_sample.csv\", index=False)\n",
        "print(\"[SUCCESS] 'test_sample.csv' saved. Use this to test your Streamlit upload.\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd5a5c4d",
        "outputId": "734668d4-2f0d-4c2a-f309-b8d519bdd144"
      },
      "source": [
        "import joblib\n",
        "\n",
        "for name, model in trained_models.items():\n",
        "    filename = f\"{name.replace(' ', '_').lower()}_model.pkl\"\n",
        "    joblib.dump(model, filename)\n",
        "    print(f\"[SUCCESS] '{filename}' saved.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUCCESS] 'logistic_regression_model.pkl' saved.\n",
            "[SUCCESS] 'decision_tree_model.pkl' saved.\n",
            "[SUCCESS] 'knn_model.pkl' saved.\n",
            "[SUCCESS] 'naive_bayes_model.pkl' saved.\n",
            "[SUCCESS] 'random_forest_model.pkl' saved.\n",
            "[SUCCESS] 'xgboost_model.pkl' saved.\n"
          ]
        }
      ]
    }
  ]
}